{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "svm_mlp.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHXBQa8MUXHd"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import copy\n",
        "from sklearn import preprocessing\n",
        "from sklearn import svm\n",
        "from sklearn.neural_network import MLPClassifier"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "391-y55bU-E8",
        "outputId": "d9dd39c3-87c1-4ec3-e940-79e8b98d85f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        }
      },
      "source": [
        "#importing the dataset and doing preprocessing...\n",
        "header_list = [\"Gender\", \"Symptoms\", \"Alcohol\", \"Hepatitis B Surface Antigen\", \"Hepatitis B e Antigen\", \"Hepatitis B Core Antibody\", \"Hepatitis C Virus Antibody\",\n",
        "\"Cirrhosis\", \"Endemic Countries\", \"Smoking\", \"Diabetes\", \"Obesity\", \"Hemochromatosis\", \"Arterial Hypertension\", \"Chronic Renal Insufficiency\",\n",
        "\"Human Immunodeficiency Virus\", \"Nonalcoholic Steatohepatitis\", \"Esophageal Varices\", \"Splenomegaly\", \"Portal Hypertension\", \"Portal Vein Thrombosis\", \"Liver Metastasis\",\n",
        "\"Radiological Hallmark\", \"Age at diagnosis\", \"Grams of Alcohol per day\", \"Packs of cigarets per year\", \"Performance Status\", \"Encefalopathy degree\", \"Ascites degree\",\n",
        "\"International Normalised Ratio\", \"Alpha-Fetoprotein\", \"Haemoglobin\", \"Mean Corpuscular Volume\", \"Leukocytes\", \"Platelets\", \"Albumin\", \"Total Bilirubin\",\n",
        "\"Alanine transaminase\", \"Aspartate transaminase\", \"Gamma glutamyl transferase\", \"Alkaline phosphatase\", \"Total Proteins\", \"Creatinine\", \"Number of Nodules\",\n",
        "\"Major dimension of nodule\", \"Direct Bilirubin\", \"Iron\", \"Oxygen Saturation\", \"Ferritin\", \"Class\"]\n",
        "\n",
        "dataset = pd.read_csv(\"hcc-data.txt\", names = header_list)\n",
        "dataset = dataset.replace({'?': np.nan})\n",
        "for col in dataset:\n",
        "  dataset[col]=dataset[col].astype(np.float)\n",
        "dataset['Class']=dataset['Class'].astype(np.int)\n",
        "#print(type(dataset['Class'][0]))\n",
        "#print(dataset.mean())\n",
        "#Handling missing values...\n",
        "dataset = dataset.fillna(dataset.mean())\n",
        "#print(dataset['Class'])\n",
        "dataset.head()"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Gender</th>\n",
              "      <th>Symptoms</th>\n",
              "      <th>Alcohol</th>\n",
              "      <th>Hepatitis B Surface Antigen</th>\n",
              "      <th>Hepatitis B e Antigen</th>\n",
              "      <th>Hepatitis B Core Antibody</th>\n",
              "      <th>Hepatitis C Virus Antibody</th>\n",
              "      <th>Cirrhosis</th>\n",
              "      <th>Endemic Countries</th>\n",
              "      <th>Smoking</th>\n",
              "      <th>Diabetes</th>\n",
              "      <th>Obesity</th>\n",
              "      <th>Hemochromatosis</th>\n",
              "      <th>Arterial Hypertension</th>\n",
              "      <th>Chronic Renal Insufficiency</th>\n",
              "      <th>Human Immunodeficiency Virus</th>\n",
              "      <th>Nonalcoholic Steatohepatitis</th>\n",
              "      <th>Esophageal Varices</th>\n",
              "      <th>Splenomegaly</th>\n",
              "      <th>Portal Hypertension</th>\n",
              "      <th>Portal Vein Thrombosis</th>\n",
              "      <th>Liver Metastasis</th>\n",
              "      <th>Radiological Hallmark</th>\n",
              "      <th>Age at diagnosis</th>\n",
              "      <th>Grams of Alcohol per day</th>\n",
              "      <th>Packs of cigarets per year</th>\n",
              "      <th>Performance Status</th>\n",
              "      <th>Encefalopathy degree</th>\n",
              "      <th>Ascites degree</th>\n",
              "      <th>International Normalised Ratio</th>\n",
              "      <th>Alpha-Fetoprotein</th>\n",
              "      <th>Haemoglobin</th>\n",
              "      <th>Mean Corpuscular Volume</th>\n",
              "      <th>Leukocytes</th>\n",
              "      <th>Platelets</th>\n",
              "      <th>Albumin</th>\n",
              "      <th>Total Bilirubin</th>\n",
              "      <th>Alanine transaminase</th>\n",
              "      <th>Aspartate transaminase</th>\n",
              "      <th>Gamma glutamyl transferase</th>\n",
              "      <th>Alkaline phosphatase</th>\n",
              "      <th>Total Proteins</th>\n",
              "      <th>Creatinine</th>\n",
              "      <th>Number of Nodules</th>\n",
              "      <th>Major dimension of nodule</th>\n",
              "      <th>Direct Bilirubin</th>\n",
              "      <th>Iron</th>\n",
              "      <th>Oxygen Saturation</th>\n",
              "      <th>Ferritin</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.129032</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>137.0</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.530000</td>\n",
              "      <td>95.000000</td>\n",
              "      <td>13.700000</td>\n",
              "      <td>106.600000</td>\n",
              "      <td>4.900000</td>\n",
              "      <td>99.000000</td>\n",
              "      <td>3.400000</td>\n",
              "      <td>2.100000</td>\n",
              "      <td>34.000000</td>\n",
              "      <td>41.000000</td>\n",
              "      <td>183.000000</td>\n",
              "      <td>150.000000</td>\n",
              "      <td>7.100000</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>0.50</td>\n",
              "      <td>85.598837</td>\n",
              "      <td>37.028941</td>\n",
              "      <td>438.997647</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.639456</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.079365</td>\n",
              "      <td>0.508065</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>62.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>20.464286</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.421851</td>\n",
              "      <td>19299.951146</td>\n",
              "      <td>12.879012</td>\n",
              "      <td>95.119753</td>\n",
              "      <td>1473.961549</td>\n",
              "      <td>113206.442654</td>\n",
              "      <td>3.445535</td>\n",
              "      <td>3.087938</td>\n",
              "      <td>67.093168</td>\n",
              "      <td>96.382716</td>\n",
              "      <td>268.026543</td>\n",
              "      <td>212.211605</td>\n",
              "      <td>8.961039</td>\n",
              "      <td>1.127089</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.8</td>\n",
              "      <td>1.93</td>\n",
              "      <td>85.598837</td>\n",
              "      <td>37.028941</td>\n",
              "      <td>438.997647</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>78.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.960000</td>\n",
              "      <td>5.800000</td>\n",
              "      <td>8.900000</td>\n",
              "      <td>79.800000</td>\n",
              "      <td>8.400000</td>\n",
              "      <td>472.000000</td>\n",
              "      <td>3.300000</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>58.000000</td>\n",
              "      <td>68.000000</td>\n",
              "      <td>202.000000</td>\n",
              "      <td>109.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>2.100000</td>\n",
              "      <td>5.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>0.10</td>\n",
              "      <td>28.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>77.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>2440.000000</td>\n",
              "      <td>13.400000</td>\n",
              "      <td>97.100000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>279.000000</td>\n",
              "      <td>3.700000</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>64.000000</td>\n",
              "      <td>94.000000</td>\n",
              "      <td>174.000000</td>\n",
              "      <td>8.100000</td>\n",
              "      <td>1.110000</td>\n",
              "      <td>2.0</td>\n",
              "      <td>15.7</td>\n",
              "      <td>0.20</td>\n",
              "      <td>85.598837</td>\n",
              "      <td>37.028941</td>\n",
              "      <td>438.997647</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>76.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.940000</td>\n",
              "      <td>49.000000</td>\n",
              "      <td>14.300000</td>\n",
              "      <td>95.100000</td>\n",
              "      <td>6.400000</td>\n",
              "      <td>199.000000</td>\n",
              "      <td>4.100000</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>147.000000</td>\n",
              "      <td>306.000000</td>\n",
              "      <td>173.000000</td>\n",
              "      <td>109.000000</td>\n",
              "      <td>6.900000</td>\n",
              "      <td>1.800000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>1.93</td>\n",
              "      <td>59.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Gender  Symptoms  Alcohol  ...  Oxygen Saturation    Ferritin  Class\n",
              "0     1.0  0.000000      1.0  ...          37.028941  438.997647      1\n",
              "1     0.0  0.639456      0.0  ...          37.028941  438.997647      1\n",
              "2     1.0  0.000000      1.0  ...           6.000000   16.000000      1\n",
              "3     1.0  1.000000      1.0  ...          37.028941  438.997647      0\n",
              "4     1.0  1.000000      1.0  ...          15.000000   22.000000      1\n",
              "\n",
              "[5 rows x 50 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYUeaE7lZ20r"
      },
      "source": [
        "#splits dataset into train, test in ratio 80:20 and does normalization on data\n",
        "def train_test_split(s_dataset):\n",
        "    features = s_dataset.columns\n",
        "    k = int(len(s_dataset.index)*0.8)\n",
        "    training_data = s_dataset.iloc[:k].reset_index(drop=True)\n",
        "    testing_data = s_dataset.iloc[k:].reset_index(drop=True)\n",
        "    scalar = preprocessing.StandardScaler()\n",
        "    training_data = scalar.fit_transform(training_data)\n",
        "    testing_data = scalar.transform(testing_data)\n",
        "    return pd.DataFrame(data = training_data, columns = features), pd.DataFrame(data = testing_data, columns = features)"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8S5nH55haPdZ"
      },
      "source": [
        "# splitting into train_X, train_Y, test_X, test_Y\n",
        "dataset = dataset.sample(frac = 1, random_state = 0).reset_index(drop = True)\n",
        "training_data,testing_data = train_test_split(dataset)\n",
        "train_X = copy.deepcopy(training_data)\n",
        "train_X = train_X.drop(['Class'], axis = 1)\n",
        "train_Y = copy.deepcopy(training_data)\n",
        "train_Y = train_Y['Class']\n",
        "for i in range(len(train_Y)):\n",
        "  if train_Y[i]>0:\n",
        "    train_Y[i]=1\n",
        "  else:\n",
        "    train_Y[i]=0\n",
        "test_X = copy.deepcopy(testing_data)\n",
        "test_X = test_X.drop(['Class'], axis = 1)\n",
        "test_Y = copy.deepcopy(testing_data)\n",
        "test_Y = test_Y['Class']\n",
        "for i in range(len(test_Y)):\n",
        "  if test_Y[i]>0:\n",
        "    test_Y[i]=1\n",
        "  else:\n",
        "    test_Y[i]=0"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PeNi8DKDaoMn",
        "outputId": "2a4c7361-e1e7-411b-acb3-10d1ffabb707",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#binary svm classifier\n",
        "c_values = [0.25, 0.5, 0.75, 1, 2, 4, 8]\n",
        "acc_linear = []\n",
        "acc_quadratic = []\n",
        "acc_rbf = []\n",
        "for x in c_values:\n",
        "  clf = svm.SVC(C = x, kernel = 'linear')\n",
        "  clf = clf.fit(train_X,train_Y)\n",
        "  print(\"Train set accuracy for linear kernel with C = \" + str(x) + \" is = \" + str(clf.score(train_X,train_Y)))\n",
        "  print(\"Test set accuracy for linear kernel with C = \" + str(x) + \" is = \" + str(clf.score(test_X,test_Y)))\n",
        "  acc_linear.append(clf.score(test_X,test_Y))\n",
        "#plt.plot(c_values,acc_linear)\n",
        "#plt.show()\n",
        "for x in c_values:\n",
        "  clf = svm.SVC(C = x, kernel = 'poly', degree = 2)\n",
        "  clf = clf.fit(train_X,train_Y)\n",
        "  print(\"Train set accuracy for quadratic kernel with C = \" + str(x) + \" is = \" + str(clf.score(train_X,train_Y)))\n",
        "  print(\"Test set accuracy for quadratic kernel with C = \" + str(x) + \" is = \" + str(clf.score(test_X,test_Y)))\n",
        "  acc_quadratic.append(clf.score(test_X,test_Y))\n",
        "#plt.plot(c_values,acc_quadratic)\n",
        "#plt.show()\n",
        "for x in c_values:\n",
        "  clf = svm.SVC(C = x, kernel = 'rbf')\n",
        "  clf = clf.fit(train_X,train_Y)\n",
        "  print(\"Train set accuracy for radial basis kernel with C = \" + str(x) + \" is = \" + str(clf.score(train_X,train_Y)))\n",
        "  print(\"Test set accuracy for radial basis function kernel with C = \" + str(x) + \" is = \" + str(clf.score(test_X,test_Y)))\n",
        "  acc_rbf.append(clf.score(test_X,test_Y))\n",
        "#plt.plot(c_values,acc_rbf)\n",
        "#plt.show()"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train set accuracy for linear kernel with C = 0.25 is = 0.9166666666666666\n",
            "Test set accuracy for linear kernel with C = 0.25 is = 0.6666666666666666\n",
            "Train set accuracy for linear kernel with C = 0.5 is = 0.9242424242424242\n",
            "Test set accuracy for linear kernel with C = 0.5 is = 0.6666666666666666\n",
            "Train set accuracy for linear kernel with C = 0.75 is = 0.946969696969697\n",
            "Test set accuracy for linear kernel with C = 0.75 is = 0.6363636363636364\n",
            "Train set accuracy for linear kernel with C = 1 is = 0.9545454545454546\n",
            "Test set accuracy for linear kernel with C = 1 is = 0.5454545454545454\n",
            "Train set accuracy for linear kernel with C = 2 is = 0.9621212121212122\n",
            "Test set accuracy for linear kernel with C = 2 is = 0.5757575757575758\n",
            "Train set accuracy for linear kernel with C = 4 is = 0.9772727272727273\n",
            "Test set accuracy for linear kernel with C = 4 is = 0.5757575757575758\n",
            "Train set accuracy for linear kernel with C = 8 is = 0.9696969696969697\n",
            "Test set accuracy for linear kernel with C = 8 is = 0.5757575757575758\n",
            "Train set accuracy for quadratic kernel with C = 0.25 is = 0.6439393939393939\n",
            "Test set accuracy for quadratic kernel with C = 0.25 is = 0.696969696969697\n",
            "Train set accuracy for quadratic kernel with C = 0.5 is = 0.75\n",
            "Test set accuracy for quadratic kernel with C = 0.5 is = 0.696969696969697\n",
            "Train set accuracy for quadratic kernel with C = 0.75 is = 0.8333333333333334\n",
            "Test set accuracy for quadratic kernel with C = 0.75 is = 0.7575757575757576\n",
            "Train set accuracy for quadratic kernel with C = 1 is = 0.8636363636363636\n",
            "Test set accuracy for quadratic kernel with C = 1 is = 0.7272727272727273\n",
            "Train set accuracy for quadratic kernel with C = 2 is = 0.9393939393939394\n",
            "Test set accuracy for quadratic kernel with C = 2 is = 0.7272727272727273\n",
            "Train set accuracy for quadratic kernel with C = 4 is = 1.0\n",
            "Test set accuracy for quadratic kernel with C = 4 is = 0.7272727272727273\n",
            "Train set accuracy for quadratic kernel with C = 8 is = 1.0\n",
            "Test set accuracy for quadratic kernel with C = 8 is = 0.6666666666666666\n",
            "Train set accuracy for radial basis kernel with C = 0.25 is = 0.6287878787878788\n",
            "Test set accuracy for radial basis function kernel with C = 0.25 is = 0.696969696969697\n",
            "Train set accuracy for radial basis kernel with C = 0.5 is = 0.9090909090909091\n",
            "Test set accuracy for radial basis function kernel with C = 0.5 is = 0.6666666666666666\n",
            "Train set accuracy for radial basis kernel with C = 0.75 is = 0.946969696969697\n",
            "Test set accuracy for radial basis function kernel with C = 0.75 is = 0.6363636363636364\n",
            "Train set accuracy for radial basis kernel with C = 1 is = 0.9696969696969697\n",
            "Test set accuracy for radial basis function kernel with C = 1 is = 0.6060606060606061\n",
            "Train set accuracy for radial basis kernel with C = 2 is = 0.9924242424242424\n",
            "Test set accuracy for radial basis function kernel with C = 2 is = 0.5454545454545454\n",
            "Train set accuracy for radial basis kernel with C = 4 is = 1.0\n",
            "Test set accuracy for radial basis function kernel with C = 4 is = 0.5757575757575758\n",
            "Train set accuracy for radial basis kernel with C = 8 is = 1.0\n",
            "Test set accuracy for radial basis function kernel with C = 8 is = 0.5757575757575758\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4ZtGSZ4SaLH"
      },
      "source": [
        "# MLP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LhDDSxL1OKWu"
      },
      "source": [
        "classifier = MLPClassifier(hidden_layer_sizes=() ,max_iter=300,activation = 'logistic',solver='sgd',random_state=1)"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLmPzX5FPiG-",
        "outputId": "7c99f44a-24c2-44ad-e888-74367772bc4a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "classifier.fit(train_X, train_Y)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(activation='logistic', alpha=0.0001, batch_size='auto',\n",
              "              beta_1=0.9, beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
              "              hidden_layer_sizes=(), learning_rate='constant',\n",
              "              learning_rate_init=0.001, max_fun=15000, max_iter=300,\n",
              "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
              "              power_t=0.5, random_state=1, shuffle=True, solver='sgd',\n",
              "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
              "              warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29VPc3AkPxXF"
      },
      "source": [
        "y_pred = classifier.predict(test_X)"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "htMrNoTEQTvM"
      },
      "source": [
        "def accuracy(confusion_matrix):\n",
        "   diagonal_sum = confusion_matrix.trace()\n",
        "   sum_of_all_elements = confusion_matrix.sum()\n",
        "   return diagonal_sum / sum_of_all_elements"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48L58aLjQA40",
        "outputId": "b42d20a4-8b92-40f7-adbc-86111fad8a38",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "#Comparing the predictions against the actual observations in y_val\n",
        "cm = confusion_matrix(y_pred, test_Y)\n",
        "\n",
        "#Printing the accuracy\n",
        "print(\"Accuracy of MLPClassifier : \", accuracy(cm))\n",
        "print(classifier.score(test_X,test_Y))"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of MLPClassifier :  0.6363636363636364\n",
            "0.6363636363636364\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}